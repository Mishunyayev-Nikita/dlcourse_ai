{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/N1keFan/noteboook/dlcourse_ai')\n",
    "PATH_TO_DATA = 'D:/Py/DataFrames/dlcourse_ai/ass_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(PATH_TO_DATA, max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 2.301697, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.301563, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.301360, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.302570, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.301918, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.301294, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.302912, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.301883, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.302292, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 9 Loss: 2.301837, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 10 Loss: 2.302072, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 11 Loss: 2.302662, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 12 Loss: 2.302661, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 13 Loss: 2.302380, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 14 Loss: 2.303170, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 15 Loss: 2.301802, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 16 Loss: 2.302476, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 17 Loss: 2.302480, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 18 Loss: 2.302157, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 19 Loss: 2.302318, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.320806, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.330815, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301827, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304413, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286279, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284880, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311257, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.306871, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304514, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265210, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289959, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.325275, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.246873, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.338132, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275569, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301404, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277644, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271363, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.322051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308033, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317549, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262630, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308261, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264990, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278636, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267083, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276510, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314133, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256404, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295822, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278750, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280567, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240982, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315651, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 2.335695, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Epoch: 20 Loss: 1.737018, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch: 40 Loss: 2.109903, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Epoch: 60 Loss: 1.498011, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch: 80 Loss: 1.243702, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch: 100 Loss: 1.273957, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch: 120 Loss: 1.371929, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 140 Loss: 1.531043, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 2.304097, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Epoch: 1 Loss: 2.281719, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Epoch: 2 Loss: 2.255189, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Epoch: 3 Loss: 2.225346, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Epoch: 4 Loss: 2.170689, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch: 5 Loss: 2.014404, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch: 6 Loss: 1.821233, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Epoch: 7 Loss: 1.688701, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch: 8 Loss: 1.642831, Train accuracy: 0.400000, val accuracy: 0.133333\n",
      "Epoch: 9 Loss: 1.564091, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch: 10 Loss: 1.336747, Train accuracy: 0.466667, val accuracy: 0.133333\n",
      "Epoch: 11 Loss: 1.234920, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch: 12 Loss: 1.247142, Train accuracy: 0.466667, val accuracy: 0.133333\n",
      "Epoch: 13 Loss: 1.394194, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch: 14 Loss: 1.036084, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch: 15 Loss: 0.790126, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch: 16 Loss: 0.675235, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch: 17 Loss: 0.569242, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch: 18 Loss: 0.485510, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch: 19 Loss: 0.408257, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 5e-3)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(momentum=0.3), learning_rate=6e-1, num_epochs=20, batch_size=100)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **40%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycle 1...\n",
      "Epoch: 0 Loss: 2.291822, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.292039, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.288015, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.278886, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.279659, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.270656, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.307670, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.256881, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.268509, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 9 Loss: 2.293191, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 2...\n",
      "Epoch: 0 Loss: 2.187485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.159175, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.095600, Train accuracy: 0.222000, val accuracy: 0.228000\n",
      "Epoch: 3 Loss: 1.942806, Train accuracy: 0.252111, val accuracy: 0.259000\n",
      "Epoch: 4 Loss: 1.749732, Train accuracy: 0.378222, val accuracy: 0.373000\n",
      "Epoch: 5 Loss: 1.483352, Train accuracy: 0.446444, val accuracy: 0.434000\n",
      "Epoch: 6 Loss: 1.366608, Train accuracy: 0.524556, val accuracy: 0.512000\n",
      "Epoch: 7 Loss: 1.734789, Train accuracy: 0.580667, val accuracy: 0.593000\n",
      "Epoch: 8 Loss: 1.454085, Train accuracy: 0.582111, val accuracy: 0.594000\n",
      "Epoch: 9 Loss: 0.982763, Train accuracy: 0.644111, val accuracy: 0.636000\n",
      "\n",
      "Cycle 3...\n",
      "Epoch: 0 Loss: 2.261962, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.215614, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.272685, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.236157, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.230311, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.256221, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.210894, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.032381, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.193284, Train accuracy: 0.205444, val accuracy: 0.212000\n",
      "Epoch: 9 Loss: 2.062301, Train accuracy: 0.230222, val accuracy: 0.235000\n",
      "\n",
      "Cycle 4...\n",
      "Epoch: 0 Loss: 2.302124, Train accuracy: 0.114556, val accuracy: 0.148000\n",
      "Epoch: 1 Loss: 2.302014, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.301571, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.302777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.301681, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.301709, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.300383, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.300219, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.302394, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 9 Loss: 2.302045, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 5...\n",
      "Epoch: 0 Loss: 2.278055, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.288229, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.283467, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.297202, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.245549, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.298729, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.298498, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.238728, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.234281, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 9 Loss: 2.183675, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 6...\n",
      "Epoch: 0 Loss: 1.850776, Train accuracy: 0.358333, val accuracy: 0.366000\n",
      "Epoch: 1 Loss: 1.744563, Train accuracy: 0.556778, val accuracy: 0.553000\n",
      "Epoch: 2 Loss: 1.404570, Train accuracy: 0.584667, val accuracy: 0.557000\n",
      "Epoch: 3 Loss: 1.408805, Train accuracy: 0.667222, val accuracy: 0.626000\n",
      "Epoch: 4 Loss: 1.043087, Train accuracy: 0.697111, val accuracy: 0.644000\n",
      "Epoch: 5 Loss: 1.389338, Train accuracy: 0.655667, val accuracy: 0.618000\n",
      "Epoch: 6 Loss: 0.862506, Train accuracy: 0.691222, val accuracy: 0.645000\n",
      "Epoch: 7 Loss: 1.124095, Train accuracy: 0.719889, val accuracy: 0.662000\n",
      "Epoch: 8 Loss: 1.604788, Train accuracy: 0.709333, val accuracy: 0.655000\n",
      "Epoch: 9 Loss: 1.110833, Train accuracy: 0.737333, val accuracy: 0.640000\n",
      "\n",
      "Cycle 7...\n",
      "Epoch: 0 Loss: 2.265681, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.247830, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.239121, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.232263, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.239946, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.218332, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.257434, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.271840, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.244626, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 9 Loss: 2.181936, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 8...\n",
      "Epoch: 0 Loss: 2.295520, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.215020, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.189889, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.213241, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.254686, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.325113, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.188714, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.206420, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.254005, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 9 Loss: 2.280989, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 9...\n",
      "Epoch: 0 Loss: 2.302713, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.300003, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.300389, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.298775, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.295850, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.297464, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.299552, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.298247, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.291766, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 9 Loss: 2.276136, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 10...\n",
      "Epoch: 0 Loss: 2.262580, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.185646, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.211295, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.270711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.249140, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.242374, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.298476, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.205464, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.218693, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 9 Loss: 2.306516, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 11...\n",
      "Epoch: 0 Loss: 2.296523, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.293142, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.295788, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.287676, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.273802, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.290285, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.273462, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.266925, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.289198, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Loss: 2.269946, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 12...\n",
      "Epoch: 0 Loss: 2.296431, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.291430, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.282390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.276792, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.287162, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.272224, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.287888, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.290665, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.275668, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 9 Loss: 2.232829, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 13...\n",
      "Epoch: 0 Loss: 2.250769, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.281485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.301640, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.188978, Train accuracy: 0.244667, val accuracy: 0.248000\n",
      "Epoch: 4 Loss: 2.091338, Train accuracy: 0.281333, val accuracy: 0.287000\n",
      "Epoch: 5 Loss: 1.939886, Train accuracy: 0.371556, val accuracy: 0.380000\n",
      "Epoch: 6 Loss: 1.752119, Train accuracy: 0.445778, val accuracy: 0.449000\n",
      "Epoch: 7 Loss: 1.637509, Train accuracy: 0.514444, val accuracy: 0.488000\n",
      "Epoch: 8 Loss: 1.506808, Train accuracy: 0.564889, val accuracy: 0.567000\n",
      "Epoch: 9 Loss: 0.963003, Train accuracy: 0.621000, val accuracy: 0.603000\n",
      "\n",
      "Cycle 14...\n",
      "Epoch: 0 Loss: 2.285716, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.279677, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.291286, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3 Loss: 2.216883, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4 Loss: 2.241997, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5 Loss: 2.319605, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6 Loss: 2.334078, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7 Loss: 2.305381, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8 Loss: 2.264370, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 9 Loss: 2.259491, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 15...\n",
      "Epoch: 0 Loss: 2.225395, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1 Loss: 2.096634, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2 Loss: 2.091459, Train accuracy: 0.262667, val accuracy: 0.254000\n",
      "Epoch: 3 Loss: 1.868844, Train accuracy: 0.323111, val accuracy: 0.329000\n",
      "Epoch: 4 Loss: 1.734016, Train accuracy: 0.444556, val accuracy: 0.438000\n",
      "Epoch: 5 Loss: 1.503322, Train accuracy: 0.513889, val accuracy: 0.504000\n",
      "Epoch: 6 Loss: 1.536367, Train accuracy: 0.523556, val accuracy: 0.536000\n",
      "Epoch: 7 Loss: 1.328787, Train accuracy: 0.620778, val accuracy: 0.605000\n",
      "Epoch: 8 Loss: 1.040181, Train accuracy: 0.660111, val accuracy: 0.628000\n",
      "Epoch: 9 Loss: 0.913119, Train accuracy: 0.647222, val accuracy: 0.656000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "from random import choice\n",
    "\n",
    "n_iterations = 15\n",
    "num_epochs = 10\n",
    "learning_rates = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "reg_strength = [1e-6, 1e-4, 1e-2]\n",
    "learning_rate_decay = [0.888, 0.995, 0.999]\n",
    "hidden_layer_size = [64, 128, 256]\n",
    "batch_size = [64]\n",
    "momentums = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "for i in range(0, n_iterations):    \n",
    "    lr = choice(learning_rates)\n",
    "    reg = choice(reg_strength)\n",
    "    lrd = choice(learning_rate_decay)\n",
    "    hs = choice(hidden_layer_size)\n",
    "    bs = choice(batch_size)\n",
    "    momentum = choice(momentums)\n",
    "    \n",
    "    model = TwoLayerNet(n_input=train_X.shape[1], n_output=10,\n",
    "                        hidden_layer_size=hs, reg=reg)\n",
    "    dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "    trainer = Trainer(model, dataset, MomentumSGD(momentum=momentum), learning_rate=lr,\n",
    "                      learning_rate_decay=lrd, num_epochs=num_epochs, batch_size=bs)\n",
    "    \n",
    "    print()\n",
    "    print (\"Cycle {}...\".format(i+1))\n",
    "    loss_hist, train_hist, val_hist = trainer.fit()\n",
    "    \n",
    "    if val_hist[-1] > best_val_accuracy:\n",
    "        best_val_accuracy = val_hist[-1]\n",
    "        best_classifier = model\n",
    "        \n",
    "        best_params['learning_rate'] = lr\n",
    "        best_params['reg_strength'] = reg\n",
    "        best_params['learning_rate_decay'] = lrd\n",
    "        best_params['hidden_layer_size'] = hs\n",
    "        best_params['batch_size'] = bs\n",
    "        best_params['momentum'] = momentum\n",
    "        \n",
    "        loss_history = loss_hist\n",
    "        train_history = train_hist\n",
    "        val_history = val_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1, 'reg_strength': 0.0001, 'learning_rate_decay': 0.999, 'hidden_layer_size': 256, 'batch_size': 64, 'momentum': 0.1}\n",
      "best validation accuracy achieved: 0.656000\n"
     ]
    }
   ],
   "source": [
    "print('Best params:', best_params)\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAGrCAYAAAB3+hgXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd8leX9//HXJ3uHEQIhAcJWZAhEke2ughtFxFGtilpHbbW1+v3V2mWtdVSqVhGte1RxIO4NyAzI3oQVZkggIUDmuX5/nINGBBLgJHdO8n4+HjzIOfeV+/7kBPLONc51m3MOERGRUBLmdQEiIiKHS+ElIiIhR+ElIiIhR+ElIiIhR+ElIiIhR+ElIiIhR+ElIiIhR+ElEmRmttbMTve6DpGGTOElIiIhR+ElUkfM7HozW2VmBWY20cxaB543M3vUzLaZWaGZLTCz7oFjw8xsiZntMrONZnant1+FSP2g8BKpA2Z2KvB3YCSQBqwDXg8cPhMYAnQBmgCXAvmBY88CNzjnEoHuwJd1WLZIvRXhdQEijcTlwHPOubkAZnY3sMPMMoFyIBE4BpjlnFta5fPKgW5mNt85twPYUadVi9RT6nmJ1I3W+HtbADjnivH3rtKdc18CjwNPAFvNbJyZJQWajgCGAevM7Bsz61/HdYvUSwovkbqxCWi374GZxQPNgY0Azrmxzrm+wHH4hw9/G3h+tnPufCAVeBf4Xx3XLVIvKbxEakekmcXs+4M/dK4xs+PNLBq4H5jpnFtrZieYWT8ziwR2AyVApZlFmdnlZpbsnCsHioBKz74ikXpE4SVSOz4E9lb5Mxj4AzAB2Ax0BEYF2iYBz+Cfz1qHfzjxocCxK4G1ZlYE3AhcUUf1i9RrpptRiohIqFHPS0REQo7CS0REQo7CS0REQo7CS0REQo5nO2ykpKS4zMxMry4vIiL10Jw5c7Y751pU186z8MrMzCQ7O9ury4uISD1kZuuqb6VhQxERCUEKLxERCTkKLxERCTkKLxERCTkKLxERCTkhfTPKsV+spHBvOWnJMbRKjgn8HUtqYjSR4cplEZGGKqTDa+76HczMKWBv+Y/vEmEGLRKiq4Ra7A/hluR/3DI5muiIcI8qFxGRoxHS4fX8NSfinKOopIIthSVsLtwb+LvE/3dRCWu272ba6nx2lVT85PObx0dV6bEFQi7ph8etkmOIiwrpl0hEpEEK+Z/MZkZybCTJsZF0bZV40HbFpf6A+1HIFfkfb9xZwpx1O9ixp/wnn5ccG/njYcmk2P2GKWNIjImszS9RRET2E/LhVVMJ0RF0Sk2gU2rCQduUlFf+0HMr2vtDDy7w96KNRWwvLj3guX88LOmfe8toGkvfdk2Jj240L7OISJ2o9qeqmbUBXgRaAT5gnHPusf3aXA7cFXhYDNzknJsf5FprXUxkOJkp8WSmxB+0TVmFj61FJWwp2hdqPw65lVu3s21XCb7APT4jw40TMpsxtEsLhnZtQdeWiZhZHX1FIiINU7V3UjazNCDNOTfXzBKBOcAFzrklVdoMAJY653aY2dnAfc65foc6b1ZWlmuoextWVPrIKy5l1bZipq7czjcr8li2ZRcALZOi/UHWJZVBnVJIjtOQo4jIPmY2xzmXVW276sLrACd+D3jcOffZQY43BRY559IPdZ6GHF4HsrlwL1NW+INsyso8ikoqCDPo3bYpQ7u0YEiXFvRITyY8TL0yEWm8aiW8zCwTmAx0d84VHaTNncAxzrnrDnBsDDAGoG3btn3XravR5sENTkWlj/m5O/lmeR7frMhjwcZCnIOmcZEM7tyCoV1aMLhLCqmJMV6XKiJSp4IeXmaWAHwD/M059/ZB2pwCPAkMcs7lH+p8ja3ndSj5xaVMXbWdb5bnMXllHtuLywA4rnVSYIixBX3aNdUbr0WkwQtqeJlZJDAJ+MQ598hB2vQE3gHOds6tqO6cCq8D8/kcSzYX8c0Kf69szrodVPocCdERDOzUnCGBMMtoGud1qSIiQRe08DL/0rgXgALn3O0HadMW+BK4yjk3rSYFKrxqpqiknGmr8vlmRR6TV+SxcedeADq2iGdol1SGdm1Bv/bNiInUbiEiEvqCGV6DgCnAQvxL5QHuAdoCOOeeMrPxwAhg3yRWRXUXV3gdPuccq/OK+TowVzZzTQFlFT6iI8I4qUPz75fjd0iJ13J8EQlJtbbaMFgUXkdvb1klM9fkfz/EmJO3G4CMprHfz5UN6JRCgt4kLSIhQuHVCG0o2PN9kE1btZ3dZZVEhBl92zVlaFd/mHVLS1KvTETqLYVXI1dW4WPOuh3fh9nSzf53NrRIjGZIZ//w4ildW2hfRhGpVxRe8iNbi0qYvCKPySu3M2VlHjv3lJMcG8n1g9tz9cD2GloUkXpB4SUHVelzzFm3g6e+Wc2Xy7bRNC6S64d04Of9M7WJsIh4SuElNTJvw07+9fkKvl6eR7P4KMYM6cBV/dvpPmYi4gmFlxyWOet28K/PVzBl5XZSEqK4YUhHrjipHbFRev+YiNQdhZcckey1BTz6+Qq+XZVPSkI0N53ckcv7tdWboEWkTii85KjMWlPAo5+tYHpOPqmJ0fzy5I6MOlEhJiK1S+ElQTF9dT6Pfr6CWWsKaJUUwy9P6cilJ7QhOkIhJiLBp/CSoHHOMX11Po98toLsdTtIS47h5lM6MTKrDVER2uleRIJH4SVB55xj6qrtPPrZCuau30l6k1huObUTF/fN0O1aRCQoFF5Sa5xzfLMij0c/X8n8DTvJaBrLrad24qI+CjEROToKL6l1zjm+Xp7Ho5+vYEFuIW2bxXHrqZ24sHc6EQoxETkCCi+pM845vli6jUc/X8HiTUVkNo/jttM6c16v1goxETksCi+pc845PluylUc/X8nSzUV0SInnttM6c26v1oSHaSd7EaleTcNLvxZL0JgZZx7Xig9uHcRTV/QhKiKM29+Yx5mPfsPE+Zvw+bz5RUlEGh6FlwRdWJhxVvc0PrxtME+M7kN4mHHba99x1mOT+WDBZoWYiBw1hZfUmrAwY3jPND7+1RD+fVlvfA5ufnUuw8ZO4aOFCjEROXIKL6l1YWHGub1a88ntQ3hs1PGUVfq46ZW5DP/3VD5ZvAWv5l1FJHRVG15m1sbMvjKzpWa22Mx+dYA2ZmZjzWyVmS0wsz61U66EsvAw4/zj0/ns10N59NJe7C2r4IaX5nDu41P5fMlWhZiI1FhNel4VwB3OuWOBk4Cbzazbfm3OBjoH/owB/hPUKqVBCQ8zLuydwee/GcpDl/SiaG8F172YzflPfMuXyxRiIlK9asPLObfZOTc38PEuYCmQvl+z84EXnd8MoImZpQW9WmlQIsLDuLhvBl/cMZQHR/SkYHcZv3g+mwuenMaUlXlelyci9dhhzXmZWSbQG5i536F0YEOVx7n8NOAwszFmlm1m2Xl5+uEkfpHhYYw8oQ1f3XkyD1zUg+27Srny2Vnc+94iSisqvS5PROqhGoeXmSUAE4DbnXNF+x8+wKf8ZOzHOTfOOZflnMtq0aLF4VUqDV5keBijTmzLV3eezPWD2/Pi9HWM+M801uXv9ro0EalnahReZhaJP7hecc69fYAmuUCbKo8zgE1HX540RlERYfzf8G48c1UW6/P3cM7YqXy0cLPXZYlIPVKT1YYGPAssdc49cpBmE4GrAqsOTwIKnXP6aSNH5YxuLfngtsF0SE3gplfmct/ExRpGFBEAImrQZiBwJbDQzOYFnrsHaAvgnHsK+BAYBqwC9gDXBL9UaYzaNIvjzRv688BHy3ju2zV8t34Hj4/uQ5tmcV6XJiIe0sa8EjI+XrSF3741HwP+eUkvfnZcK69LEpEg08a80uCc1b0VH942mMyUeG54aQ5/mbSEsgqf12WJiAcUXhJS2jSL480b+3P1gEyenbqGkU9PJ3fHHq/LEpE6pvCSkBMdEc595x3Hk5f3YfW2YoaPncoXS7d6XZaI1CGFl4SsYT3SeP/WQWQ0jeXaF7K5/8OllFdqGFGkMVB4SUjLTIlnwk0DuOKktoybnMOocTPYtHOv12WJSC1TeEnIi4kM568X9ODfl/Vm+ZZdDB87ha+WbfO6LBGpRQovaTDO7dWa928dRKvkWK55fjYPfLSMCg0jijRICi9pUNqnxPPOLwdw2Ylteeqb1Vz2zAy2FJZ4XZaIBJnCSxqcmMhw/n5RDx4bdTyLNxUxbOwUvlmhuxiINCQKL2mwzj8+nYm3DKJFQjQ/f24WD32yXMOIIg2EwksatE6pCbx780AuzWrD41+t4vLxM9lWpGFEkVCn8JIGLzYqnH9c3JOHL+nFgtxCho2dwtSV270uS0SOgsJLGo0RfTOYeMtAmsZFceVzM3nksxVU+rzZmFpEjo7CSxqVzi0Tee+WgVzUO4OxX6zkymdnsm2XhhFFQo3CSxqduKgIHh7Zi39e3JO563cw7LGpTFulYUSRUKLwkkbrkqw2vHfzIJJjI7ji2Zk89vlKDSOKhAiFlzRqXVslMvGWQZx/fDqPfr6Cnz83i+3FpV6XJSLVUHhJoxcfHcEjI3vxwEU9mL22gGGPTWFGTr7XZYnIISi8RAAzY9SJbXn35oEkREcw+pkZPPHVKnwaRhSpl6oNLzN7zsy2mdmigxxPNrP3zWy+mS02s2uCX6ZI3Tg2LYmJtw5ieM/W/POT5Vz9/GzyNYwoUu/UpOf1PHDWIY7fDCxxzvUCTgYeNrOooy9NxBsJ0RGMHXU8f7uwOzNy8hk+diqz1xZ4XZaIVFFteDnnJgOH+p/rgEQzMyAh0LYiOOWJeMPMuLxfO96+aQAxkWGMGjeD/3y9WsOIIvVEMOa8HgeOBTYBC4FfOecOuPupmY0xs2wzy87L0y7fUv91T0/m/VsHcdZxrfjHx8u49oXZ7Nhd5nVZIo1eMMLrZ8A8oDVwPPC4mSUdqKFzbpxzLss5l9WiRYsgXFqk9iXGRPL46N785fzj+HZVPsPGTmHWGg0jingpGOF1DfC281sFrAGOCcJ5ReoNM+PK/plMuGkAURFhXDpuOvd/uJSS8kqvSxNplIIRXuuB0wDMrCXQFcgJwnlF6p0eGcl8eNtgLjuxLeMm53De41NZtLHQ67JEGp2aLJV/DZgOdDWzXDO71sxuNLMbA03+Agwws4XAF8BdzjltFCcNVnx0BPdf2IPnrzmBwr3lXPDEt4z9YqVudClSh8w5b1ZPZWVluezsbE+uLRIsO/eUce97i5k4fxO9MpJ5eOTxdEpN8LoskZBlZnOcc1nVtdMOGyJHoUlcFGMv680To/uwvmAPw8dO4dmpa7SkXqSWKbxEgmB4zzQ++fUQBnVK4S+TljB6/Aw2FOzxuiyRBkvhJRIkqYkxjP95Fg+O6MmijUWc/dgU3pi9Hq+G5kUaMoWXSBCZGSNPaMNHvxpM9/Qk7pqwkOteyNbdmkWCTOElUgvaNIvj1etO4t5zujF11XbOfHQykxZs8roskQZD4SVSS8LCjF8Mas8Htw2mXbM4bnn1O2597Tt27tH2UiJHS+ElUss6pSYw4aYB3HFGFz5auJkzH53MV8u3eV2WSEhTeInUgYjwMG49rTPv3jyQJnGRXPPf2dz99kJ2l+oGDCJHQuElUoe6pycz8ZZB3DCkA6/PXs9Zj03WJr8iR0DhJVLHYiLDuXvYsbwxpj+Gcem46fztgyXa5FfkMCi8RDxyYvtmfPSrwYw+sS3PTFnDuf+eysJcbfIrUhMKLxEPxUdH8LfAJr9FJeVc+OS3PPb5Ssq1ya/IISm8ROqBk7um8untQxneM41HP1/BiP9MY9W2XV6XJVJvKbxE6onkuEgeG9WbJy/vw4aCPQwbO5XxU3K0ya/IASi8ROqZYT38m/wO6ZzCXz9YymXPaJNfkf0pvETqodTEGJ65KosHL+7J4k1FnPWvydrkV6QKhZdIPWVmjMxqw8e3D6ZHRjJ3TVjItS9ks61Im/yKKLxE6rmMpj9s8vvtqu2c+S9t8iui8BIJAT/a5Ld5vDb5lUav2vAys+fMbJuZLTpEm5PNbJ6ZLTazb4Jboojs0yk1gQk39tcmv9Lo1aTn9Txw1sEOmlkT4EngPOfcccAlwSlNRA6k6ia/TeOiApv8LqBYm/xKI1JteDnnJgOH2jl0NPC2c259oL1+DRSpA93Tk5l460BuGNqB12dv4OzHJjMzJ9/rskTqRDDmvLoATc3sazObY2ZXHayhmY0xs2wzy87LywvCpUUat+iIcO4++1j+d4N/k99Rz8zgz+8vYVdJudelidSqYIRXBNAXGA78DPiDmXU5UEPn3DjnXJZzLqtFixZBuLSIAJyQ+cMmv899u4ZTHvqa12etp1K7c0gDFYzwygU+ds7tds5tByYDvYJwXhE5DPs2+Z14y0Aym8fz+7cXcu6/pzJ9tYYSpeEJRni9Bww2swgziwP6AUuDcF4ROQI9M5rw5o39+fdlvSncW85lz8zgxpfmsD5fW0xJwxFRXQMzew04GUgxs1zgj0AkgHPuKefcUjP7GFgA+IDxzrmDLqsXkdpnZpzbqzVndGvJ+Ck5PPn1ar58ZBvXDMrkllM6kRgT6XWJIkfFvNorLSsry2VnZ3tybZHGZmtRCQ9+vJwJc3NJSYjizjO7cklWG8LDzOvSRH7EzOY457Kqa6cdNkQagZZJMTw8spfmw6TBUHiJNCKaD5OGQuEl0sjsmw/74o6h3HlmFyavzOP0R77h7x8t1fvDJGQovEQaqZjIcG45tTNf3Xky5/ZqzdPf5Oj9YRIyFF4ijZzmwyQUKbxEBNB8mIQWhZeIfO9g82EPfLRM82FSryi8ROQn9p8Pe+qb1Zzy0De8MVvzYVI/KLxE5KB+PB8Wx10T/PNhM3TrFfGYwktEqrX/fNiocZoPE28pvESkRjQfJvWJwktEDovmw6Q+UHiJyBHRfJh4SeElIkdF82HiBYWXiBw1zYdJXVN4iUjQaD5M6orCS0SCTvNhUtsUXiJSaw40H3bF+JlMXpGHV3dxl4bBvPoHlJWV5bKzsz25tojUvZLySl6Ytpbnvl3D1qJSjk1L4oYhHRjeM43IcP0eLX5mNsc5l1VtO4WXiNSl0opK3pu3iWcm57ByWzGtk2P4xaD2jDqxLQnREV6XJx6raXhV++uOmT1nZtvMbFE17U4ws0ozu/hwChWRxiU6IpyRWW345PYhPHd1Fm2axfHXD5Yy4O9f8I+Pl7GtqMTrEiUEVNvzMrMhQDHwonOu+0HahAOfASXAc865t6q7sHpeIrLPvA07GTd5NR8v2kJEWBgX9k7n+iHt6ZSa6HVpUsdq2vOqto/unJtsZpnVNLsVmACcUKPqRESqOL5NE568vC/r8nczfsoa3pyzgTeyN3D6samMGdKREzKbYmZelyn1yFHPkppZOnAh8FQN2o4xs2wzy87LyzvaS4tIA9OueTx/uaA7035/Gref3pm563cy8unpXPjkND5etFnvFZPv1WjBRqDnNelAw4Zm9ibwsHNuhpk9H2inYUMROWp7yyp5a84GnpmyhvUFe8hsHsd1gztwcd8MYiLDvS5PakFQVxtWE15rgH39+RRgDzDGOffuoc6p8BKRmqr0OT5ZvIWnJ+cwf8NOmsdHcVX/TK7q346m8VFelydBVGfhtV+751HPS0RqiXOOWWsKGDc5hy+WbSMmMoyRWW24blAH2jaP87o8CYKgLdgws9eAk4EUM8sF/ghEAjjnqp3nEhEJFjOjX4fm9OvQnJVbdzFucg6vzVrPyzPWcXaPNG4Y0oGeGU28LlPqgN6kLCIhbWtRCf/9di2vzFjHrtIKTurQjBuGdOTkri20QjEEaYcNEWlUdpWU8/qsDTz37Ro2F5bQpWUC1w/uwPnHpxMVoe2nQoXCS0QapfJKH+/P38S4yTks27KLVkkxXDMwk8v6tSUpJtLr8qQaCi8RadScc0xeuZ2nv1nNtNX5JERHMLpfW64ZmElacqzX5clBKLxERAIWbSzk6ck5fLBgE2FmnHd8a8YM6cAxrZK8Lk32o/ASEdnPhoI9PDt1DW/M3sDe8kpO7tqCMUM60L9Dcy3uqCcUXiIiB7Fjdxkvz1jHC9PXsr24jB7pyYwZ0oGzu7ciQvcW85TCS0SkGiXllbw9dyPjp+SQs303rZNjuKhPBiP6ZtA+Jd7r8holhZeISA35fI7Plm7l1ZnrmbIyD5+DPm2bMKJvBuf0bE1yrFYp1hWFl4jIEdhaVMK7321kwtxcVmwtJioijDO6teTivhkM7pSiYcVapvASETkKzjkWbixkwpxcJs7fxI495bRIjObC3umM6JNB11a6UWZtUHiJiARJWYWPL5dtY8LcXL5ato0Kn6N7ehIX98ngvOPTaaad7YNG4SUiUgvyi0t5b94mJszNZfGmIiLDjVO6pjKibwandE3VVlRHSeElIlLLlm0pYsKcXN75bhPbi0tpFh/Feb1aM6JPBt3Tk/TesSOg8BIRqSMVlT6mrNzOW3Nz+WzJVsoqfHRtmciIvulccHw6qUkxXpcYMhReIiIeKNxTzvsL/MOK363fSZjBkC4tGNEngzO6tSQmMtzrEus1hZeIiMdW5xXz9txc3pm7kU2FJSTGRHBOz9Zc3DeDPm2baFjxABReIiL1hM/nmJ6Tz4Q5uXy0aAt7yytpnxLPiD7pXNgng/Qm2uV+H4WXiEg9VFxawYcLNzNhTi4z1xRgBv07NGdEnwzO7tGKuKgIr0v0lMJLRKSe21Cwh7fn+nfzWF+wh7iocIb1SGNEnwz6tW9GWFjjG1YMWniZ2XPAOcA251z3Axy/HLgr8LAYuMk5N7+6Cyu8RET8nHPMXruDCXNy+WDhZopLK8hoGstFvdO5qE8GmY1ok+BghtcQ/KH04kHCawCw1Dm3w8zOBu5zzvWr7sIKLxGRn9pbVsmnS7bw1pxcpq7ajnOQ1a4pI/pmcOoxqbRs4MvugzpsaGaZwKQDhdd+7ZoCi5xz6dWdU+ElInJoWwpLeCewSfCqbcUAtE+J56QOzTmpQzP6d2je4N5D5lV43Qkc45y77iDHxwBjANq2bdt33bp11V5bRKSxc86xZHMR01fnM311PrPWFLCrtAKADi38Yda/Q3P6dWhGamJoh1mdh5eZnQI8CQxyzuVXd071vEREjkylz7F4UyEzcvxhNnvtDooDYdYpNSHQK0uhX4dmpCREe1zt4anT8DKznsA7wNnOuRU1KVDhJSISHBWVPhZtKqoSZgXsKasEoEvLhCo9s+b1fgf8OgsvM2sLfAlc5ZybVtMCFV4iIrWjvNLHwo0/9Myy1+5gb7k/zI5plRiYM2tOv/bNaFrPwiyYqw1fA04GUoCtwB+BSADn3FNmNh4YAeybwKqoyYUVXiIidaO80seC3J3MyClgRo6/Z1ZS7sMMjmmVxEkdmvkDrX1zkuMiPa1Vb1IWEZEDKqvwh9n01fnMWOPvmZVW+MPs2FZJ9O/o75md2L4ZybF1G2YKLxERqZHSikrmbyj0h1lOPnPW76AsEGbHtU6if2CY8YT2zUiKqd0wU3iJiMgRKSmvZN6Gnd+H2Xfrd1JW6SPMoHt68vdhlpXZlMQgh5nCS0REgqKkvJK563cwY3U+M3IK+G7DDsorHeFhRvf0ZE7q0IxBnVIY3LnFUV+rpuHVuLcvFhGRasVEhjOgYwoDOqYA/i2s5q7f8X3P7Nkpa5ixOj8o4VVTCi8RETkssVHhDOyUwsBO/jDbU1bBtqLSOq1B4SUiIkclLiqCzJS6jZOwOr2aiIhIECi8REQk5Ci8REQk5Ci8REQk5Ci8REQk5Hj2JmUzy+OHzXyPRgqwPQjnaYz02h05vXZHTq/dkWsMr10751y1bxjzLLyCxcyya/JubPkpvXZHTq/dkdNrd+T02v1Aw4YiIhJyFF4iIhJyGkJ4jfO6gBCm1+7I6bU7cnrtjpxeu4CQn/MSEZHGpyH0vEREpJFReImISMgJ2fAys7PMbLmZrTKz33tdT6gwszZm9pWZLTWzxWb2K69rCjVmFm5m35nZJK9rCSVm1sTM3jKzZYF/f/29rilUmNmvA/9fF5nZa2YW43VNXgvJ8DKzcOAJ4GygG3CZmXXztqqQUQHc4Zw7FjgJuFmv3WH7FbDU6yJC0GPAx865Y4Be6DWsETNLB24Dspxz3YFwYJS3VXkvJMMLOBFY5ZzLcc6VAa8D53tcU0hwzm12zs0NfLwL/w+QdG+rCh1mlgEMB8Z7XUsoMbMkYAjwLIBzrsw5t9PbqkJKBBBrZhFAHLDJ43o8F6rhlQ5sqPI4F/0APmxmlgn0BmZ6W0lI+RfwO8DndSEhpgOQB/w3MOQ63szivS4qFDjnNgIPAeuBzUChc+5Tb6vyXqiGlx3gOa35PwxmlgBMAG53zhV5XU8oMLNzgG3OuTle1xKCIoA+wH+cc72B3YDmqmvAzJriH1lqD7QG4s3sCm+r8l6ohlcu0KbK4wzUja4xM4vEH1yvOOfe9rqeEDIQOM/M1uIfqj7VzF72tqSQkQvkOuf29fLfwh9mUr3TgTXOuTznXDnwNjDA45o8F6rhNRvobGbtzSwK/+TlRI9rCglmZvjnHZY65x7xup5Q4py72zmX4ZzLxP9v7kvnXKP/DbgmnHNbgA1m1jXw1GnAEg9LCiXrgZPMLC7w//c0tNiFCK8LOBLOuQozuwX4BP/Km+ecc4s9LitUDASuBBaa2bzAc/c45z70sCZpHG4FXgn8wpkDXONxPSHBOTfTzN4C5uJfLfwd2iZK20OJiEjoCdVhQxERacQUXiIiEnIUXiIiEnIUXlLvBfYSLDaztnV83evM7Oua1FC17RFe61Mzu/xIP1+ksVF4SdAFfsjv++Mzs71VHh/2D2jnXKVzLsE5t/4wahhiZpMP91rBrOFgzOyvZvb8fuc/0zn3ytGeW6SxCMml8lK/OecS9n0ceEPvdc65zw/W3swinHMVQS5jGKDl/x6rpe+tiHpeUvcCPY83Ard22AVcYWb9zWyGme00s81mNjawEwhmFmFmLrAXI2b2cuD4R2a2y8ymm1n7/S4zDPgwsIfeA/td/wMzuy3w8f8zs5zAeRab2XkHqXn/GlqY2SQzKzKzGfi37qna/nEzyw0cn23/dQNVAAAgAElEQVRmAwLPn4N/b8TLAz3ROYHnp5rZ1YGPw8zsXjNbZ2bbzOz5wMa2mFmnQB1XBc6fZ4e4JZCZnWdm8wJf33oz+8N+x4cEXvdCM9tgZlcGno8zs0cDn1NoZpPNLNrMTg/8QlL1HLlmdvKRfG8Dn9PDzD43swIz22JmvzOzdDPbY2ZNqrTrFziuX7pF4SWeuRB4FUgG3sD/5stfASn430h9FnDDIT5/NPAHoBn+HQj+su+A+Xd+b+KcWxC4xigzs8Cx5sCpgWsCrAhcLxn4G/CqmbWsQf3/AXYBrYAxwC/2Oz4T6Bmo7y3gTTOLds5NAh7EvzVXgnOu7wHOfR1wBXAy0BFoiv92IlUNADoBPwP+ZGadD1JnceBcycC5wK8CAUog8D8AHgGa49+keWHg8x4N1N8v8DXcQ803I67x99bMkoHPgfeBNKAL8HVgM9qpwCVVznsF8Jp6cgIKL/HOVOfc+845n3Nur3NutnNupnOuwjmXg38HgaGH+Py3nHPZgb3eXgGOr3JsOPBR4OOvgUhg340PRwJTnHNbAZxz/wvcJsbnnHsVWAtkHarwQK/hAuAPzrk9gZB8qWob59xLzrmCwA/aB4Ek/GFTE5cDDznn1gRuW3MPMNrMqv5/vc85VxK4vc1i/PfH+gnn3JfOuUWBr28+/j0Z972uV+C/v9b/Aq/7dufcPPPfL+9q4LbAa1PpnJsaeK1r4nC+t+cBG5xzjznnSp1zRc65WYFjLwRqJNDbupT9XmdpvBRe4pWqt7TBzI4JDOdtMbMi4M/4f1M/mC1VPt4DJFR5/P18l3POh/+3/8sCx0bjD7t9173azOYHhrR2AsdUc12Alvi3Jav6Nazb7+v5nfnvGFwI7ADia3DefVrvd751QBTQYt8Tgb0C99n/669aR38z+zowvFiIv1e3r442wOoDfFrLwPUOdKwmDud72wZYdZDzvAP0Mv8Kz7OAvH33ohNReIlX9t+X7GlgEdDJOZcE3MuBb31zSGYWjX9oquoCkdeAkYFhsj74fyhiZh3wD//dBDR3zjUBltXgulvxD6FVvbPB90vozewU4DfACKAJ/mG/4irnrW5Ptk1Au/3OXYb/fliH63X8dxBo45xLxn8TzX11bMA/LLm/rYHrHejYbvw3QwS+7xE136/N4XxvD1YDzrk9gdovx78fp3pd8j2Fl9QXiUAhsNvMjuXQ812HMhSY65zbve8J59zswLnHAR9WuX9ZAv4ftHn4N9y/Dn/P65ACw2fv4p9rijWz7vh/uFb9WiqA7fiHLO/D3/PaZyuQuW8e7gBeA35jZplmloh/Lu61QC/ycCUCBc65EjM7iR/fPv5l4CwzGxFYkJJiZr2cc5XA88C/zKyV+d/jNjAwXLoMSDSznwUe/zHwNVZXw8G+txOBtmZ2i5lFmVmSmZ1Y5fiL+OcThwfqFQEUXlJ/3AH8HP8iiKf5YUHF4TrYEvnX8N8X6dV9TwTmqsYCs/DfofYYan5X6Zvw96i24r/FzH+rHPsQf89vJf45tKLA+fd5A/+wXIGZzeKnngm0mYJ/9/Vd+Bc8HImbgL8HVv7dA/xv3wHn3Br8izjuAgrw71reI3D41/hvuzEncOx+/Bt578C/O/wLwMbAsapDmAdy0O+tc64QOAN/L3Ub/gU0Vec6J+Mfop3pnMs9vC9dGjLtKi8NipmtAM5xzq3wuhYJDvO/2fw559zzXtci9Yd6XtJgmFkM8KyCq+EIDHV2B970uhapX9TzEpF6ycxewT/XdatzTos15EcUXiIiEnI0bCgiIiHHsz3CUlJSXGZmpleXFxGRemjOnDnbnXMtqmvnWXhlZmaSnZ3t1eVFRKQeMrN11bfSsKGIiIQghZeIiIQchZeIiIQchZeIiIQchZeISAgor/Sh9+X+QLfTFhGpp3buKePjRVv4YOFmpq3OJyo8jLTkGNKaxNAqKfb7j9OSY0hL9j9Ojo3k4DcsaDgUXiIi9Ujh3nI+XewPrKkrt1Phc7RrHse1g9rj8zk2F5awuXAv01dvZ+uuUip9P+6NxUaGk5YcQ6vAn9bJsf6/qwRek7ggBdyeAlg/HdZNg/AoOP2PR3/OGlJ4iYh4bFdJOZ8v3cqk+ZuZvDKP8kpHRtNYrhvcgXN6pnFc66QDhk1FpY/txWVsLtwbCLUSNu/cy+aiErYUljBjdf4BAy4mMoy05FhaJf2057Yv8A4YcIUbA2H1LaybDnlL/c+HR0OXM2vr5TkghZeIiAd2l1bwxbJtTJq/ia9X5FFW4aN1cgxXD8hkeM/W9MpIrrZ3FBEe9n0Pq/dB2lT6HHm7StlcuJcthSVsKixhS5Wwm5lTwJaikgMEnJGVuJPBUSvp7ZbQpWQBTUo3+c8ZmUBl+glE9rgYazcAWveByJhgvCw1pvASEakje8sq+XLZNj5YuIkvl22jpNxHy6RoLu/XlnN6tqZ3myaEhQV3vio8zL4PuIOp9Dm279rLjrXzqcyZSuyWWaQWzCFhTz7sgR0kMdPXlVmVpzLTdwxLS9pRuSyc6FVhpCWX0ir5O3plNOHuYccGtfZDUXiJiNSikvJKvl6ex6QFm/hi6Tb2lleSkhDNyKw2nNOzNVntmgY9sGqkshw2zYP10whfN42W66fTsqTQfywpHY45FdoNgHYDaZrShdMd9C4u5dz9em6bA483FZbUafkKLxGRICutqGTKiu1MWrCJz5duo7i0gmbxUVzYJ51zeqbRr31zwus6sMr2wMZs/+KKddMgdzaU7/Efa94Jup0PbQf4A6tJW9hvyDLcIDUphtSkGGjTpG5rPwCFl4hIEJRV+Ph29XYmzd/Mp0u2sKukguTYSIb3SOOcXmn079CciPA6fGttSSGsnxlYXDENNn0HvnLAoFV36H1loGc1ABJS666uIFF4iYgcoYpKH9NW5/PBgs18vHgLhXvLSYyJ4GfHtWJ4zzQGdUohsq4Cq3jbD72q9dNgyyLAQVgktO4N/W/2B1WbfhDrfc/paCm8REQOQ6XPMTMnn/cXbOaTxVso2F1GQnQEZ3RryfAeaQzukkJ0RHjtFuEc7FxfZdn6NMhf5T8WEQttToSTf+8Pq/QsiIqr3Xo8oPASEalGpc+RvbaASQs289GizWwvLiMuKpzTjm3JOT3TGNqlBTGRtRhYvkrYvtLfo1oXeFNwUa7/WEwytO0Pfa7yz1ml9YKIqNqrpZ5QeImIHIDP55i7fgeTFmzmw4Wb2barlJjIME49JpVzerbmlK6pxEbVQmBVVkD+Sv9KwM3zYPN82LwAynf7jye0DMxV3e4PrdRuENb4tqlVeImIBDjnmLdhJx8s2MwHCzezubCEqIgwTu7SgnN6tea0Y1KJjw7ij83KCshb9kNIbZoHWxZCxV7/8cg4aNUDel8BrY/3z1c16/CTlYCNkcJLRAR4Y/Z6xn6xio079xIZbgzt0oLfndWV049tSWJM5NFfoKLMv53Spn29qXmwdTFUBN4fFZUArXpC1jX+ob+04yGlM4TV8vxZiFJ4iUijVlHp468fLOX5aWvp264pt5/emTOPa0Vy7FEEVkWpP5j2hdSmebBtCVSW+Y9HJ/kD6oTr/CHV+nho1rFRDv8dKYWXiDRahXvLufW175i8Io/rBrXn7mHHHv6bh8v3BoJq3g+9qm1LA++pwr+gIq0X9LvRH1Jpx0PT9gqqo6TwEpFGae323Vz7wmzW5e/hgYt6MOrEttV/Utke2Lrox4spti0FV+k/HtvUH04Dbvlh6K9ppuaoaoHCS0QanRk5+dz48hwAXrq2H/07Nv9po9Ji/+KJqospti8H5/Mfj0vx96S6/OyHob/kNgqqOlKj8DKzs4DHgHBgvHPugQO0GQncBzhgvnNudBDrFBEJijdmr+f/3llEu+ZxPHf1CbRrHu8/sGMtLJ30wzzV9pX4f5wB8an+cDr23MDQXy//5rUKKs9UG15mFg48AZwB5AKzzWyic25JlTadgbuBgc65HWYWehtliUiDVulz3P/hUp6duoYhXVrw+OjeJMVE+ocCpz4K3z4GlaWQmObvSXUf8cPQX1Ka1+XLfmrS8zoRWOWcywEws9eB84ElVdpcDzzhnNsB4JzbFuxCRUSO1K6Scm577Tu+Wp7H1QMy+X/DjyUizGDJRPjkHijcAN0vhtPuhabtvC5XaqAm4ZUObKjyOBfot1+bLgBm9i3+ocX7nHMf738iMxsDjAFo27YGk6MiIkdpQ8Eern1hNqvzdvPXC7pzxUntIG85fPQ7yPkaUo+Dqz+AzEFelyqHoSbhdaBBXbff4wigM3AykAFMMbPuzrmdP/ok58YB4wCysrL2P4eISFDNXlvADS/NodLnePEXJzKwTTR8+v9gxn8gMh7OfhCyroVwrV0LNTX5juUCbao8zgA2HaDNDOdcObDGzJbjD7PZQalSROQwvZm9gXveWUibpnGMv6ovHbZ8BP/+AxRv8W+3dNp9kNDC6zLlCNUkvGYDnc2sPbARGAXsv5LwXeAy4HkzS8E/jJgTzEJFRGqi0ud48ONlPD05h4GdmvPU6dEkTrrEf/uQ1r1h1CuQkeV1mXKUqg0v51yFmd0CfIJ/Pus559xiM/szkO2cmxg4dqaZLQEqgd865/Jrs3ARkf0Vl1Zw++vz+HzpVq7LasLdsW8R/sKzENMEzn0Mel+lnS0aCHPOm6mnrKwsl52d7cm1RaThyd2xh+teyGbl1kJe6r2SAWsfh707/HNap9wDcc28LlFqwMzmOOeq7RprllJEQt6cdTu44aVsOles4Lu010lasgDanATD/glpPb0uT2qBwktEQto73+XywFvfcl/s/ziHz6GsJVw4DnqO1A4YDZjCS0RCks/nePiTxeyaOo4voiYQ7yuB/rfA0LsgJsnr8qSWKbxEJOTsKavgiedf5JzcRzk2cj2+dkOxYQ9C6jFelyZ1ROElIiFlS+4alrx4O78t+5ri2Fa4814grNv5GiJsZBReIhIaKsrY+OmjNJn1CINcBWuP+yWZF/w/iIr3ujLxgMJLROq/1V+y6507SC/O4duwLFqPepT2XbSKsDFTeIlI/bVzPe7je7Bl75Pva8kTzf7EmOt/SbP4KK8rE48pvESk/ikvgWljcVMeobzSx2PlIynoeT33jehLdES419VJPaDwEpH6wzlY8TF8/HvYsZZvowZy1+5L+fnZg7hzcAdMizIkQOElIvVD/mp/aK38lJImnbgj4o98XdKNx67szendWnpdndQzCi8R8VbZbpj8EEx/HMKjWdLjLkbO60FyfDxvXZvFsWl6w7H8lMJLRLzhHCx5Fz75PyjaiOt5Kc/GXsNfvymgb7umPH1lX1ISor2uUuophZeI1L1tS+HD38LaKdCyB6UXPMOdM+N4f9YmLuqdzv0X9SAmUgsz5OAUXiJSd0oK4et/wMynIDoRhj3Eti6juf6VeczfsInfndWVm4Z21MIMqZbCS0RqV9FmWP2l/8+qz/0B1vfncOq9LNoZwfX/mcHOPeU8dUVfzureyutqJUQovEQkuMr3wrppPwTWtiX+5+NTocvPoN8NkN6Xjxdt4ddvzKZJXCRv3tif7unJ3tYtIUXhJSJHxzn/HNbqL/xhtW4aVJRAeBS07Q+n/wk6nQapx0FYGM45nvxqFf/8ZDnHt2nCuKv6kpoY4/VXISFG4SUih2/3dsj5+ofe1a7N/udTukLWL6DjqdBuIETF/ejTSsorufvthbzz3UbO69WaBy/uqYUZckQUXiJSvYoyyJ0FqwK9q83zAQcxTaDjKdDxVFyHU9gTm0bB7jK2F5dSsHoX+bvzyS8uo2B3Kfm7y1i0sZAVW4u544wu3HJqJy3MkCOm8BKRn3IOl7+asuWfUbnqS6I3fEt4xW58Fs7WpB6sSL+O7yL7Mq8yk/wtlRSsLmN78SJKKxYc8HTREWGkJESTkhDFfy7vw9k90ur4C5KGRuEl0kg459hdVklBcRnbd5dSUFzm7yUFPt5TlE+rgll03jWLXqVzac02ooF1vlQm+/ozxdeD6b7j2LU3jpiCMJrHR9M8oZLmCVF0bplA8/gomidE0yw+6vuPm8dH0Sw+iriocPWyJKgUXiINyOq8Yj5dvJX8Yv8wXf5u/5CdP7DKKKvwfd82DB+9bDVDwhYwLGIhPW0VEfjYa3GsTuzDgmZXUZA2mMiUjqQnRPHL+Gj+EB9F84Qo4qL0o0O8pX+BIg1AcWkF//5iJc9OXUOFzxEbGU7zBH8PqEVCNF1bJpGSEEXb8Hy6Fs+m7c4ZNNs6jYiyIhyGte4Nne6AjqcSm3EC3cMj6e71FyVyCAovkRDmnGPi/E3c/+FSthaVMjIrgzvP7EpqUmDpeWkxrPv2h4UW+Sv9zye2huPOg46nYh1Ogbhm3n0RIkegRuFlZmcBjwHhwHjn3AP7Hb8a+CewMfDU48658UGsU0T2s3zLLu59bxEz1xTQPT2J/1zRlz5tmsCWBTA/EFbrZ4CvHCJiIXMgZF0DHU+DFl1Bc1ASwqoNLzMLB54AzgBygdlmNtE5t2S/pm84526phRpFpIqiknL+9dlKXpi+lsSYCP52YXdGndCW8NxZMP5u2DjH37BldzjpJv97rtr2h0i9EVgajpr0vE4EVjnncgDM7HXgfGD/8BKRWuSc4+25G/n7R8vI313KZSe25bdndqVp+RaY8AtY/DYkpsHwR+CY4ZCofQKl4apJeKUDG6o8zgX6HaDdCDMbAqwAfu2c27B/AzMbA4wBaNu27eFXK9JILd5UyB/fW0z2uh0c36YJz12dRc8W4TD1AZj2OFgYDL0LBv4KouK9Llek1tUkvA40MO72e/w+8JpzrtTMbgReAE79ySc5Nw4YB5CVlbX/OURkP4V7ynn4s+W8PGMdTeKieHBETy7unUbYgtfg9b9A8VboMRJO/yMkZ3hdrkidqUl45QJtqjzOADZVbeCcy6/y8BngH0dfmkjj5fM53pyzgX98vJyde8q48qR2/OaMriRvnQHjL4MtCyHjRBj1KmRkeV2uSJ2rSXjNBjqbWXv8qwlHAaOrNjCzNOdcYGdOzgOWBrVKkUZkQe5O7n1vMfM27CSrXVP+dP6JHBe9HSZeDcsmQXIbGPEsdB+hFYPSaFUbXs65CjO7BfgE/1L555xzi83sz0C2c24icJuZnQdUAAXA1bVYs0iDtGN3GQ9+spzXZ6+neXw0D1/Si4u6xWOTH4SZT/tvMXLqH6D/zRAZ63W5Ip4y57yZesrKynLZ2dmeXFukPqn0OV6btZ6HPl3OrpIKft4/k9tPa0/S4lfgq/thTwH0vtwfXFpBKA2cmc1xzlU7Fq4dNkQ8NHf9Dv743mIWbiykX/tm/Pn87nQtngn//QXkLYV2g+Cs+yGtl9elitQrCi8RD2wvLuUfHy3jzTm5tEyKZuxlvTk3rQj77Bew8lNo2h4ufRmOOUfzWiIHoPASqUMVlT5embmehz9dzp6ySm4Y0oFb+zcnYfo/4d1nISoBzvwrnDgGIqK9Llek3lJ4idSR2WsLuPe9xSzdXMSgTincN7wznda+Dk8/AKW7oO81cMo9EJ/idaki9Z7CS6SWbSsq4e8fLeOd7zbSOjmGJ0f35uyoedibN0HBav/egz+7H1KP9bpUkZCh8BKpJeWVPl6YtpZ/fb6SsgofN5/SkVuOKyX2ixthzTeQ0gVGvwmdz9C8lshhUniJ1ILpq/P548RFrNhazNAuLfjz6am0m/cIPPsSxCTD2f/0354kPNLrUkVCksJLJIi2FJbwtw+X8v78TWQ0jWX86O6cVvg29vLDULEX+t0IQ38HsU29LlUkpCm8RIKgrMLHc9+uYewXK6nwOX51aidubrWYqC/PhZ3roMvZ/lWEKZ28LlWkQVB4iRylKSvz+OPExeTk7eb0Y1vylxPLSZt+O0ybBqnHwVXvQYeTvS5TpEFReIkcoY079/LXSUv4aNEW2jWP45VL2zJw7ZPwxqsQ3wLOfQx6Xwlh4V6XKtLgKLxEDlNpRSXPTM7h8a9WAfD709pybfgkIj8cC74KGHg7DL4DYpI8rlSk4VJ4iRyGbUUljB4/k1Xbihl2XCp/6bSM5tPvgKKN0O0COONP0DTT6zJFGjyFl0gN5ReXcvn4mWzauZcJ50bQd8ld8MkcSDseRoyHdgO8LlGk0VB4idRA4d5yrnpuFlsLdvJ1l3dJ/extSEyDC56CnpdCWJjXJYo0KgovkWoUl1Zw9X9nsXHrNr5Jf5qmObNg8J0w+DcQFe91eSKNksJL5BBKyiu57oXZrM/N5ZuW/yZ5+1L/EGGPi70uTaRRU3iJHERpRSU3vDSHNWtW81XKIyTt2giXvgJdz/K6NJFGT+ElcgDllT5uffU7clYu4osmD5FQWgRXTIDMQV6XJiIovER+otLnuON/81mzdA6fJP6TOCrh5xMhvY/XpYlIgMJLpAqfz3HP2wtZt2Ay78c/TEx0HFw5CVKP8bo0EalC4SUS4Jzjz5OWsH7ux7wZ+yhRian+fQn1pmORekfhJYI/uB78ZDkbZkzgpeh/E968I1z1LiS28ro0ETkAhZcI8PiXq9g4+UXGRT1FWOvjscvfgrhmXpclIgeh8JJGb/yUHLZ++QT/inoeyxyEXfYaRCd6XZaIHEKN9rQxs7PMbLmZrTKz3x+i3cVm5swsK3glitSeV2auI//jf/DXyP9C55/5e1wKLpF6r9rwMrNw4AngbKAbcJmZdTtAu0TgNmBmsIsUqQ1vz9lA0fv/x12Rr1PZ/RLCRr0MkTFelyUiNVCTnteJwCrnXI5zrgx4HTj/AO3+AjwIlASxPpFa8cH8XEre/RU3RbxPRZ9fEH7ROAiP9LosEamhmoRXOrChyuPcwHPfM7PeQBvn3KRDncjMxphZtpll5+XlHXaxIsHw5eJcKt+6ntHhX1A+4HYizn1Eu8KLhJia/I+1Azznvj9oFgY8CtxR3Ymcc+Occ1nOuawWLVrUvEqRIJm2NBd74wrOC59Gycn3Ennmn8AO9E9cROqzmqw2zAXaVHmcAWyq8jgR6A58bf4fAq2AiWZ2nnMuO1iFihytOSvWEfH6KE4KW8ruMx8mfsB1XpckIkeoJuE1G+hsZu2BjcAoYPS+g865QiBl32Mz+xq4U8El9cniVTlEv3Ixx9haioc/RdIJo7wuSUSOQrXDhs65CuAW4BNgKfA/59xiM/uzmZ1X2wWKHK1Vq5YT8/K5dLYNFJ3/vIJLpAGo0ZuUnXMfAh/u99y9B2l78tGXJRIc61YtIublC2nKLgoveo3Unqd7XZKIBIF22JAGa8vKucS/ciERVLLjkglkHDfQ65JEJEi0PlgapO3LvyXulXPxYeSPfFfBJdLAKLykwdm5+AviXruIQhdP/siJdOym3cpEGhqFlzQoxfMnEvfmpWx0KeRfOpFju/X0uiQRqQUKL2kw9sx5ldh3fs5S15b8S97l+G66+7FIQ6XwkgahbPrTxLz/S2b5jmHnxW9yUvfOXpckIrVI4SUhr/zrh4j65Hd8WdmbnRe+xtAeHb0uSURqmZbKS+hyjspP7yVy+ljeqRyIO+8JLuqd6XVVIlIHFF4SmnyV+Cb9mvC5L/BixRmEDf8nV5zQ3uuqRKSOaNhQQk9lOW7C9YTNfYHHK86n7Mx/cEV/BZdIY6Kel4SW8r24//0cW/kJfy+/jPhT7+C6IZrjEmlsFF4SOkqKcK9dCuumc3f5tSQPGsOtp3byuioR8YDCS0LD7nx4+SJ8WxZye9nNND9pNHed1RXTjSRFGiWFl9R/RZvgxQuoKFjL9aW/IbXPedx7TjcFl0gjpvCS+q0gB148n7Jd+Vy593e06nUa91/Ug7AwBZdIY6bwkvpr62J46UJKS0u5eM/dpB3bn4cu6UW4gkuk0dNSeamfcrPhv8PYW+E4Z/c9NOvcj3+P7k1kuP7JiojCS+ob52DxO/DCeewJT+Ssov+jWbuePHVFX6Ijwr2uTkTqCQ0bSv1RtBk+uAOWf0BRsx6cvfWXpGa049mrTyA2SsElIj9QeP3/9u49PKr6zuP4+5sbkECCqIAQwOAigQI1EPFSQQVUlNtDrYo8WBdxWVtY6Sq6q2u1Vdra1iIorBbQQitKVcSCm0KgIltQEZCLXBaCgBCIEAQDCiG37/6RtI0YZBISTk7yef2TnJnfc+bz/DKZz5wz58yR4LnDh7Mg81G8+ATrU+9j+MYepLRIYubInjRuoKepiHyVXhUkWJ99DAvGwa6/knteT3507C5WrEukR7tzmHZHD5IaxQadUERqIZWXBKO4CN6bgr/zC4oslqmNxjIp+wpSWyYy/fsd6depuc7jEpFTUnnJ2ZezAZ8/FstZz8q4K7j3yAgSzktm8rAODOrWSudwichpqbzk7CnMh2W/xFdMJs8SeahgHOvjenP/zRdzc/dkYnQYvIhESOUlZ8euFZyYN5YGeTt4rehqnm8wku8PuIRJl7XVIfAiUmkRlZeZ9QcmA9HADHd/8qT77wHGAMXAF8Bod99czVkljPKPkLfgYZI2/YH9JeczIerHpPUbyltXtiM+Tu+dRKRqTvvqYWbRwFTgOiAbWGVm808qp5fd/fmy8YOBiUD/GsgrIZK7+k1iF46nSeFBZjKAI1f+B09d05nEhjqCUETOTCRvfXsC2919B4CZzQGGAH8vL3c/Um58AuDVGVLC5UDOHj794zi6ff4Xtnob5n1rBkMGDKZZQlzQ0USkjoikvFoDe8otZwOXnTzIzMYA9wFxQJ+KVmRmo4HRAG3btq1sVqnlPjuaz/I3ptJ7x0RSyWfJBXfT9bbHGHlOYtDRRKSOiaS8Kjpu+WtbVu4+FZhqZsOBR4A7KxgzDZgGkJ6erq2zOiLveCF/XLyCzmseZYitZ2d8F/K/O4V+HdKCjiYidVQk5ZUNtCm3nAzs+4bxc4DnziSUhMOxgiJmLv+Yo//7HGP9ZaKjosi9asPi3OIAAAnISURBVAIp146BKB32LiI1J5LyWgV0MLMUYC8wDBhefoCZdXD3rLLFAUAWUmflFxbz8srd/HnpUh4qnEr3qO0cbXstCTc/S8OmbU6/AhGRM3Ta8nL3IjMbCyyi9FD5F919k5k9Dqx29/nAWDPrBxQCh6lgl6GEX2FxCXPXZPPfSzYz9MtXeSX2T9CoCdw0jSbdbgV9nZOInCURnWjj7hlAxkm3PVru93HVnEtqkZISZ8GGfTy9eBtND23gD/Ev0C72E+jyPbjxl5BwXtARRaSe0VmickruTubm/UzM3Mbu/bn8LOlNhjZYAAmtYOCrcPENQUcUkXpK5SVf4+78Nesgv8ncyvrsPG5tuo15zaYTf2wvXHo39H0MGurwdxEJjspLvmLVrkP8etFWPth5iNSkIpb+01xSsv8E53aA2xZCuyuCjigiovKSUh9l5/FU5laWbcvl/MZxzLpsL723/wrbdxh6jYfeD0Bsw6BjiogAKq96b9v+o0zM3MbCTZ/SND6WJ/o0Y/jBZ4henwEXXAJ3zIOWXYOOKSLyFSqvemr3Z8d4esk23ly3l4S4GMb1uYh7EpfTaOlPobgQrnsCLv8hROspIiK1j16Z6pm844VMeTuLme/uIjrKGN2rPT/sBkmL74d3l8OFvWDwM9CsfdBRRUROSeVVTxQVl/DKB7t5ekkWh48VcEuPZO7vdxEtNk6HmU9CdAMY/Cyk3aGTjUWk1lN51QPLtuUy4a3NZB34gsvbN+ORAZ3pwscw50b4dAN0GgQ3PQVNWgYdVUQkIiqvOmz7gaNM+J8tvLM1l3bnxjNteFeu431s4U9gz/vQuAXc+nvoPCToqCIilaLyqoMOf1nApCXbeGnlbuLjovnFtUncYouJWXg3HDtY+nnW9T+DtBHQqGnQcUVEKk3lVYcUFJXw+/d28cxfsjh2ooDHOuUwjMXEvbe49HOsjjfBpaMg5RpdskREQk3lVQe4O0u2HODnGVv4/GAOD7dYzXdLMonbsbt012DvB6DHnZCUHHRUEZFqofIKuS05R3hiwSbyd77Pwwnv0Dd+BVF5haWHvN/wU0gdCDFxQccUEalWKq+Qyj16gikL11K47lUei11Cxwaf4NFNsO4jIX0UNE8NOqKISI1ReYVMfmExb2a+TfEHMxjPMprEHqe4eRfoOQnregs0aBx0RBGRGqfyCgkvOsHazNnY6hkMK9lEocWSf/Eg6PUDopMv1YnFIlKvqLxqu7xs9i99nrgNL9G95DA5US3YlfYgF/b7V2J1BWMRqadUXrVRSQnsWEr+e9OJ+3gR57uzPKo7Jel30av/MKJj9GcTkfpNr4K1ybFDsG42JateJOrwDr70RGaVDKKkxz8zon8vmjSMDTqhiEitoPKqDfaugVUv4BvnYkX5fGSpvFAwBus0mPEDutGmWXzQCUVEahWVV1AKjsHGubBqBuSsozgmnsyYPkz+sjexrbry44Gd6ZnSLOiUIiK1ksrrbDuYBatfhHWzIT+PwnM7Mq/5vTy+uxsJiefw4PdSGZrWmqgoHT0oInIqKq+zobgItmaUbmXtXAZRsRR2HMRrdj0/2ZBElBmj+17EPVe3Jz5OfxIRkdPRK2VNOpIDH86CNbPg6D5ITKbk2kdYENWXJ5Yd4uAXJxia1ooHbuhIq6aNgk4rIhIaEZWXmfUHJgPRwAx3f/Kk++8D7gaKgFzgLnf/pJqzft30PpCzvsYfpspKikp/XtQXBvyGd6O7MyEji805OXRv25QZd6ZzSRtdkkREpLJOW15mFg1MBa4DsoFVZjbf3TeXG7YWSHf3Y2b2A+BXwG01Efgrvn07tL+mxh+mymLj4VtD2eUt+XnGFjI3r6F100Y8e3saA7tdgOlbMUREqiSSLa+ewHZ33wFgZnOAIcDfy8vdl5Yb/z4wojpDnjrZv5yVh6mqvOOFTHk7i5nvLiMuOooHbujIqKtSaBgbHXQ0EZFQi6S8WgN7yi1nA5d9w/hRwJ8rusPMRgOjAdq2bRthxFO795W1ZB344ozXU1P2fX6cI/mF3NIjmfHXd6R5YsOgI4mI1AmRlFdF+7a8woFmI4B04OqK7nf3acA0gPT09ArXURnNmzTgeGHxma6mxqS2bMKoq1Lo0jop6CgiInVKJOWVDbQpt5wM7Dt5kJn1A/4LuNrdT1RPvG/2yMDOZ+NhRESklomKYMwqoIOZpZhZHDAMmF9+gJmlAb8FBrv7geqPKSIi8g+nLS93LwLGAouALcCr7r7JzB43s8Flw34NNAZeM7N1Zjb/FKsTERE5YxGd5+XuGUDGSbc9Wu73ftWcS0RE5JQi2W0oIiJSq6i8REQkdFReIiISOuZ+xqdbVe2BzXKB6vj+w/OAg9WwnvpIc1d1mruq09xVXX2Yu3bufv7pBgVWXtXFzFa7e3rQOcJIc1d1mruq09xVnebuH7TbUEREQkflJSIioVMXymta0AFCTHNXdZq7qtPcVZ3mrkzoP/MSEZH6py5seYmISD2j8hIRkdAJbXmZWX8z22pm283sP4POExZm1sbMlprZFjPbZGbjgs4UNmYWbWZrzeytoLOEiZk1NbPXzez/yp5/VwSdKSzM7N/L/l83mtkrZlbvr2wbyvIys2hgKnAj0Bm43cx0ca/IFAH3u3sn4HJgjOau0sZReoUFqZzJwEJ3TwW+jeYwImbWGrgXSHf3LkA0pZemqtdCWV5AT2C7u+9w9wJgDjAk4Eyh4O457v5h2e9HKX0BaR1sqvAws2RgADAj6CxhYmaJQG/gBQB3L3D3z4NNFSoxQCMziwHiqeCCwPVNWMurNbCn3HI2egGuNDO7EEgDVgabJFQmAQ8CJUEHCZn2QC7wu7JdrjPMLCHoUGHg7nuBp4DdQA6Q5+6ZwaYKXljLyyq4Tcf8V4KZNQbmAj9y9yNB5wkDMxsIHHD3NUFnCaEYoDvwnLunAV8C+qw6AmZ2DqV7llKAVkCCmY0INlXwwlpe2UCbcsvJaDM6YmYWS2lxzXb3N4LOEyLfAQab2S5Kd1X3MbOXgo0UGtlAtrv/bSv/dUrLTE6vH7DT3XPdvRB4A7gy4EyBC2t5rQI6mFmKmcVR+uHl/IAzhYKZGaWfO2xx94lB5wkTd3/I3ZPd/UJKn3Nvu3u9fwccCXf/FNhjZh3LbuoLbA4wUpjsBi43s/iy/9++6GAXYoIOUBXuXmRmY4FFlB5586K7bwo4Vlh8B7gD+MjM1pXd9rC7ZwSYSeqHfwNml73h3AGMDDhPKLj7SjN7HfiQ0qOF16KvidLXQ4mISPiEdbehiIjUYyovEREJHZWXiIiEjspLRERCR+UlIiKho/ISEZHQUXmJiEjo/D9FnAChyKU8ngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.564000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
